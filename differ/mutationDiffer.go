// Copyright (c) 2018 Couchbase, Inc.
// Licensed under the Apache License, Version 2.0 (the "License"); you may not use this file
// except in compliance with the License. You may obtain a copy of the License at
//   http://www.apache.org/licenses/LICENSE-2.0
// Unless required by applicable law or agreed to in writing, software distributed under the
// License is distributed on an "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND,
// either express or implied. See the License for the specific language governing permissions
// and limitations under the License.

package differ

import (
	"encoding/json"
	"fmt"
	"io/ioutil"
	"math"
	"os"
	"reflect"
	"strings"
	"sync"
	"sync/atomic"
	"time"
	"xdcrDiffer/base"
	"xdcrDiffer/utils"

	"github.com/couchbase/gocbcore/v10"
	xdcrBase "github.com/couchbase/goxdcr/base"
	xdcrCrMeta "github.com/couchbase/goxdcr/crMeta"
	hlv "github.com/couchbase/goxdcr/hlv"
	xdcrLog "github.com/couchbase/goxdcr/log"
	"github.com/couchbase/goxdcr/metadata"
	xdcrUtils "github.com/couchbase/goxdcr/utils"
)

type MutationDiffer struct {
	sourceBucketName      string
	sourceBucketUUID      string
	sourceReference       *metadata.RemoteClusterReference
	targetBucketName      string
	targetBucketUUID      string
	targetReference       *metadata.RemoteClusterReference
	inputDiffKeysFileName string
	srcDiffKeysFileName   string
	tgtDiffKeysFileName   string
	mutationDifferFileDir string
	numberOfWorkers       int
	batchSize             int
	timeout               int
	conflictRetries       int
	retriesWaitSec        int

	sourceBucketAgent *GocbcoreAgent
	targetBucketAgent *GocbcoreAgent

	missingFromSource map[uint32]map[string]*GetResult
	missingFromTarget map[uint32]map[string]*GetResult
	srcDiff           map[uint32]map[string][]*GetResult
	tgtDiff           map[uint32]map[string][]*GetResult
	deletedFromSource map[uint32]map[string][]*GetResult
	deletedFromTarget map[uint32]map[string][]*GetResult

	keysWithError []*MutationDifferFetchEntry
	stateLock     *sync.RWMutex

	numKeysProcessed  uint32
	numKeysWithErrors uint32

	maxNumOfSendBatchRetry int
	sendBatchRetryInterval time.Duration
	sendBatchMaxBackoff    time.Duration
	compareType            string

	logger *xdcrLog.CommonLogger

	sourceDcpAgent *gocbcore.DCPAgent
	targetDcpAgent *gocbcore.DCPAgent

	colIdsMap           map[uint32][]uint32
	reverseTgtColIdsMap map[uint32][]uint32

	srcCapability metadata.Capability
	tgtCapability metadata.Capability

	migrationHintMap MigrationHintMap
	duplicateMap     DuplicatedHintMap

	srcKvSSLPortMap xdcrBase.SSLPortMap
	tgtKvSSLPortMap xdcrBase.SSLPortMap
	srcKvVbMap      map[string][]uint16
	tgtKvVbMap      map[string][]uint16
	utils           xdcrUtils.UtilsIface
}

func (r *GetResult) MarshalJSON() ([]byte, error) {
	var dataToBeEncoded map[string]interface{} = make(map[string]interface{})

	// GetMetaResult nil implies that the compareType is "body only"
	if r.GetMetaResult == nil {
		dataToBeEncoded[base.JsonBody] = r.Value
		return json.Marshal(dataToBeEncoded)
	}

	// compareType can either be "meta only" or "both body and meta"
	if r.Value != nil { // indicates compareType is "both body and meta"
		dataToBeEncoded[base.JsonBody] = r.Value
	}

	dataToBeEncoded[base.JsonMetadata] = r.GetMetaResult
	if r.HLV != nil {
		dataToBeEncoded[xdcrCrMeta.XATTR_CVCAS_PATH] = r.GetCvCas()
		dataToBeEncoded[xdcrCrMeta.XATTR_SRC_PATH] = r.GetCvSrc()
		dataToBeEncoded[xdcrCrMeta.XATTR_VER_PATH] = r.GetCvVer()
		dataToBeEncoded[xdcrCrMeta.XATTR_PV_PATH] = r.GetPV()
		dataToBeEncoded[xdcrCrMeta.XATTR_MV_PATH] = r.GetMV()
		dataToBeEncoded[base.Updated] = r.Updated
	}
	return json.Marshal(dataToBeEncoded)
}

func NewMutationDiffer(sourceBucketName string, sourceBucketUUID string, sourceRef *metadata.RemoteClusterReference, targetBucketName string, targetBucketUUID string, targetRef *metadata.RemoteClusterReference, fileDifferDir string, mutationDifferFileDir string, numberOfWorkers int, batchSize int, timeout int, maxNumOfSendBatchRetry int, sendBatchRetryInterval time.Duration, sendBatchMaxBackoff time.Duration, compareType string, logger *xdcrLog.CommonLogger, colIdsMap map[uint32][]uint32, srcCapability metadata.Capability, tgtCapability metadata.Capability, xdcrUtils xdcrUtils.UtilsIface, retries int, retriesWaitSecs int, duplMapping DuplicatedHintMap) *MutationDiffer {
	// this indicates that mutation differ is expected to read srcDiff fetchList generated by file differ,
	inputDiffKeysFileName := fileDifferDir + base.FileDirDelimiter + base.DiffKeysFileName
	if len(colIdsMap) == 0 {
		// legacy mode
		colIdsMap = make(map[uint32][]uint32)
		colIdsMap[0] = []uint32{0}
	}
	return &MutationDiffer{
		sourceBucketName:       sourceBucketName,
		sourceBucketUUID:       sourceBucketUUID,
		sourceReference:        sourceRef,
		targetBucketName:       targetBucketName,
		targetBucketUUID:       targetBucketUUID,
		targetReference:        targetRef,
		inputDiffKeysFileName:  inputDiffKeysFileName,
		mutationDifferFileDir:  mutationDifferFileDir,
		numberOfWorkers:        numberOfWorkers,
		batchSize:              batchSize,
		timeout:                timeout,
		missingFromSource:      make(map[uint32]map[string]*GetResult),
		missingFromTarget:      make(map[uint32]map[string]*GetResult),
		srcDiff:                make(map[uint32]map[string][]*GetResult),
		tgtDiff:                make(map[uint32]map[string][]*GetResult),
		deletedFromSource:      make(map[uint32]map[string][]*GetResult),
		deletedFromTarget:      make(map[uint32]map[string][]*GetResult),
		keysWithError:          MutationDiffFetchList{},
		stateLock:              &sync.RWMutex{},
		maxNumOfSendBatchRetry: maxNumOfSendBatchRetry,
		sendBatchRetryInterval: sendBatchRetryInterval,
		sendBatchMaxBackoff:    sendBatchMaxBackoff,
		compareType:            compareType,
		logger:                 logger,
		colIdsMap:              colIdsMap,
		reverseTgtColIdsMap:    compileReverseMap(colIdsMap),
		srcDiffKeysFileName:    utils.DiffKeysFileName(true, fileDifferDir, base.DiffKeysFileName),
		tgtDiffKeysFileName:    utils.DiffKeysFileName(false, fileDifferDir, base.DiffKeysFileName),
		srcCapability:          srcCapability,
		tgtCapability:          tgtCapability,
		utils:                  xdcrUtils,
		conflictRetries:        retries,
		retriesWaitSec:         retriesWaitSecs,
		duplicateMap:           duplMapping,
	}
}

func (d *MutationDiffer) Run() error {
	srcDiffKeys, tgtDiffKeys, migrationHintMap, err := d.loadDiffKeys()
	if err != nil {
		return err
	}
	d.migrationHintMap = migrationHintMap

	srcPovFetchList, srcPovFetchIdx := srcDiffKeys.ToFetchEntries(d.colIdsMap, migrationHintMap)
	tgtPovFetchList, tgtPovFetchIdx := tgtDiffKeys.ToFetchEntries(d.reverseTgtColIdsMap, nil)
	combinedFetchList := dedupFetchLists(srcPovFetchList, srcPovFetchIdx, tgtPovFetchList, tgtPovFetchIdx)

	d.logger.Infof("Mutation srcDiff to work on %v srcPovFetchList with diffs.\n", len(combinedFetchList))

	err = d.initialize()
	if err != nil {
		d.logger.Errorf("Error initializing: %v\n", err)
		return err
	}

	d.fetchAndDiff(combinedFetchList)

	// Retry multiple times if asked to, in order to minimize in flight differences
	for i := 0; d.containsDiff() && i < d.conflictRetries; i++ {
		if i > 0 {
			d.logger.Infof("Waiting %v seconds before retrying...", d.retriesWaitSec)
			time.Sleep(time.Duration(d.retriesWaitSec) * time.Second)
		}
		srcDiffKeys = d.getDiffKeysFromSourceGocbResult()
		tgtDiffKeys = d.getDiffKeysFromTargetGocbResult()
		srcPovFetchList, srcPovFetchIdx = srcDiffKeys.ToFetchEntries(d.colIdsMap, migrationHintMap)
		tgtPovFetchList, tgtPovFetchIdx = tgtDiffKeys.ToFetchEntries(d.reverseTgtColIdsMap, nil)
		combinedFetchList = dedupFetchLists(srcPovFetchList, srcPovFetchIdx, tgtPovFetchList, tgtPovFetchIdx)
		d.logger.Infof("With %v diffs, retrying %v out of %v times to resolve in-flight differences...",
			len(combinedFetchList), i+1, d.conflictRetries)
		d.fetchAndDiff(combinedFetchList)
	}

	return d.writeDiff()
}

func (d *MutationDiffer) fetchAndDiff(combinedFetchList MutationDiffFetchList) {
	// First clear the results that the differWorker will be working on
	d.clearGoCbResults()
	finCh := make(chan bool)

	go d.reportStatus(len(combinedFetchList), finCh)
	loadDistribution := utils.BalanceLoad(d.numberOfWorkers, len(combinedFetchList))
	waitGroup := &sync.WaitGroup{}
	for i := 0; i < d.numberOfWorkers; i++ {
		lowIndex := loadDistribution[i][0]
		highIndex := loadDistribution[i][1]
		if lowIndex == highIndex {
			// skip workers with 0 load
			continue
		}
		diffWorker := NewDifferWorker(d, d.sourceDcpAgent, d.targetDcpAgent, d.sourceBucketAgent, d.targetBucketAgent,
			combinedFetchList[lowIndex:highIndex], waitGroup, d.colIdsMap, d.reverseTgtColIdsMap, d.migrationHintMap,
			d.compareType, d.conflictRetries)
		waitGroup.Add(1)
		go diffWorker.run()
	}
	waitGroup.Wait()
	close(finCh)
}

func dedupFetchLists(srcPovList MutationDiffFetchList, srcIdx MutationDiffFetchListIdx, tgtPovList MutationDiffFetchList, tgtIdx MutationDiffFetchListIdx) MutationDiffFetchList {
	// The goal is to combine and deduplicate into a single source-side view of the fetch list
	var combinedFetchList MutationDiffFetchList
	combinedFetchIdx := make(MutationDiffFetchListIdx)

	// First go through the source side - and make sure that all matching entries are fetched
	for _, srcFetchEntry := range srcPovList {
		combinedEntry := srcFetchEntry.Clone()

		potentialTgtEntries, exists := tgtIdx[combinedEntry.Key]
		if !exists {
			// Make sure this entry at least has non nil src list
			if len(combinedEntry.TgtColIds) == 0 {
				panic("Will be missing target")
			}
		}
		// potentialTgtEntries are based off of the index and so need to ensure that only matching entries are combined
		for _, chkTgtEntry := range potentialTgtEntries {
			var foundMatching bool
			// From target's pov, the TgtColIds are to be source's
			for _, chkSrcId := range chkTgtEntry.TgtColIds {
				if chkSrcId == combinedEntry.SrcColId {
					// This entry matches
					foundMatching = true
					// Make sure that this target's colId exists in the centralized fetch list
					var foundTgt bool
					for _, chkTgtId := range combinedEntry.TgtColIds {
						// chkTgtEntry is from tgt's pov... ensure that tgt's pov, the srcColId is covered
						if chkTgtId == chkTgtEntry.SrcColId {
							foundTgt = true
							break
						}
					}
					if !foundTgt {
						// This target's colId needs to be in the combinedEntry to ensure it is fetched from target KV
						combinedEntry.TgtColIds = append(combinedEntry.TgtColIds, chkTgtEntry.SrcColId)
					}
					break
				}
			}
			if foundMatching {
				break
			}
		}
		combinedFetchList = append(combinedFetchList, combinedEntry)
		combinedFetchIdx.AddEntry(combinedEntry)
	}

	// Now, go through the target side to ensure that if anything the source missed, it is covered
	for _, tgtFetchEntry := range tgtPovList {
		potentialCombinedEntries, exists := combinedFetchIdx[tgtFetchEntry.Key]
		if !exists {
			// This means that this key is not even being fetched from the source at all
			// need to add it to be fetched so that the diff algo can find it
			srcEntries := tgtFetchEntry.Reverse()
			for _, addOneEntry := range srcEntries {
				combinedFetchList = append(combinedFetchList, addOneEntry)
				combinedFetchIdx.AddEntry(addOneEntry)
			}
			continue
		}

		// Key is being fetched from the source but need to check to make sure that the right colId is being fetched
		// since we are working off of the index
		for _, chkSrcColId := range tgtFetchEntry.TgtColIds {
			var foundSourceEntry bool
			for _, potentialEntry := range potentialCombinedEntries {
				if potentialEntry.SrcColId == chkSrcColId {
					foundSourceEntry = true
					break
				}
			}
			if foundSourceEntry {
				break
			} else {
				// From target's pov, the sourceColId -> tgtMap entry is missing
				// This means that for a key that exists in the source's collection, it isn't aware that
				// this target collection also needs to be fetched
				// Add them into the combinedFetchList
				srcEntries := tgtFetchEntry.Reverse()
				for _, addOneEntry := range srcEntries {
					combinedFetchList = append(combinedFetchList, addOneEntry)
					combinedFetchIdx.AddEntry(addOneEntry)
				}
			}
		}
	}
	return combinedFetchList
}

func (d *MutationDiffer) reportStatus(totalKeys int, finCh chan bool) {
	ticker := time.NewTicker(time.Duration(base.StatsReportInterval) * time.Second)
	defer ticker.Stop()

	var prevNumKeysProcessed uint32 = math.MaxUint32

	for {
		select {
		case <-ticker.C:
			numKeysProcessed := atomic.LoadUint32(&d.numKeysProcessed)
			numKeysWithErrors := atomic.LoadUint32(&d.numKeysWithErrors)
			if prevNumKeysProcessed != math.MaxUint32 {
				d.logger.Infof("%v Mutation differ processed %v fetchList out of %v fetchList. processing rate=%v key/sec\n", time.Now(), numKeysProcessed, totalKeys, (numKeysProcessed-prevNumKeysProcessed)/base.StatsReportInterval)
			} else {
				d.logger.Infof("%v Mutation differ processed %v fetchList out of %v fetchList.\n", time.Now(), numKeysProcessed, totalKeys)

			}
			if numKeysWithErrors > 0 {
				d.logger.Warnf("%v skipped %v fetchList because of errors\n", time.Now(), numKeysWithErrors)
			}
			if numKeysProcessed == uint32(totalKeys) {
				return
			}
			prevNumKeysProcessed = numKeysProcessed
		case <-finCh:
			return
		}
	}
}

func (d *MutationDiffer) writeDiff() error {
	err := d.writeKeysWithError()
	if err != nil {
		d.logger.Errorf("Error writing fetchList with errors. err=%v\n", err)
	}

	err = d.writeCollectionMapping()
	if err != nil {
		d.logger.Errorf("Error collection mapping with errors. err=%v\n", err)
	}

	err = d.writeDiffDetails()
	if err != nil {
		d.logger.Errorf("Error writing srcDiff details. err=%v\n", err)
	}

	err = d.writeMigrationDetails()
	if err != nil {
		d.logger.Errorf("Error writing migration details. err=%v\n", err)
	}
	return err
}

func (d *MutationDiffer) writeDiffDetails() error {
	diffBytes, err := d.getDiffBytes()
	if err != nil {
		return err
	}
	return d.writeDiffBytesToFile(diffBytes)
}

func (d *MutationDiffer) writeCollectionMapping() error {
	fileName := base.MutationDiffColIdMapping
	srcMapFilename := d.mutationDifferFileDir + base.FileDirDelimiter + fileName

	srcMappingBytes, srcErr := json.Marshal(d.colIdsMap)
	if srcErr != nil {
		d.logger.Errorf("Unable to marshal colIdsMap: %v\n", d.colIdsMap)
	} else {
		srcErr = ioutil.WriteFile(srcMapFilename, srcMappingBytes, 0644)
	}

	if srcErr != nil {
		return srcErr
	} else {
		return nil
	}
}

func (d *MutationDiffer) writeKeysWithError() error {
	keysWithErrorBytes, err := json.Marshal(d.keysWithError)
	if err != nil {
		return err
	}

	keysWithErrorFileName := d.mutationDifferFileDir + base.FileDirDelimiter + base.DiffErrorKeysFileName
	keysWithErrorFile, err := os.OpenFile(keysWithErrorFileName, os.O_RDWR|os.O_CREATE, base.FileModeReadWrite)
	if err != nil {
		return err
	}

	defer keysWithErrorFile.Close()

	_, err = keysWithErrorFile.Write(keysWithErrorBytes)
	return err
}

func (d *MutationDiffer) getDiffBytes() ([]byte, error) {
	outputMap := map[string]interface{}{
		"Mismatch":          d.srcDiff,
		"MissingFromSource": d.missingFromSource,
		"MissingFromTarget": d.missingFromTarget,
	}
	if d.compareType == base.MutationCompareTypeMetadata || d.compareType == base.MutationCompareTypeBodyAndMeta {
		outputMap["DeletedFromSource"] = d.deletedFromSource
		outputMap["DeletedFromTarget"] = d.deletedFromTarget
	}
	return json.Marshal(outputMap)
}

func (d *MutationDiffer) writeDiffBytesToFile(diffBytes []byte) error {
	fileName := base.MutationDiffFileName
	fullFileName := d.mutationDifferFileDir + base.FileDirDelimiter + fileName

	diffFile, err := os.OpenFile(fullFileName, os.O_RDWR|os.O_CREATE, base.FileModeReadWrite)
	if err != nil {
		return err
	}

	defer diffFile.Close()

	_, err = diffFile.Write(diffBytes)
	return err

}

func (d *MutationDiffer) loadDiffKeys() (DiffKeysMap, DiffKeysMap, MigrationHintMap, error) {
	srcDiffKeysBytes, err := ioutil.ReadFile(d.srcDiffKeysFileName)
	if err != nil {
		return nil, nil, nil, err
	}

	tgtDiffKeyBytes, err := ioutil.ReadFile(d.tgtDiffKeysFileName)
	if err != nil {
		return nil, nil, nil, err
	}

	// migration hint map may or may not exist
	var migrationHintFound bool
	migrationHintFile := fmt.Sprintf("%v_%v", d.srcDiffKeysFileName, base.DiffKeysSrcMigrationHintSuffix)
	migrationHintBytes, err := ioutil.ReadFile(migrationHintFile)
	if err == nil {
		migrationHintFound = true
	}

	srcDiffKeys := make(DiffKeysMap)
	tgtDiffKeys := make(DiffKeysMap)
	migrationHintMap := make(MigrationHintMap)

	err = json.Unmarshal(srcDiffKeysBytes, &srcDiffKeys)
	if err != nil {
		return nil, nil, nil, fmt.Errorf("srcUnmarshal %v", err)
	}
	err = json.Unmarshal(tgtDiffKeyBytes, &tgtDiffKeys)
	if err != nil {
		return nil, nil, nil, fmt.Errorf("tgtUnmarshal %v", err)
	}

	if migrationHintFound {
		err = json.Unmarshal(migrationHintBytes, &migrationHintMap)
		if err != nil {
			return nil, nil, nil, fmt.Errorf("hintUnmarshal %v", err)
		}
	}

	return srcDiffKeys, tgtDiffKeys, migrationHintMap, nil
}

func (d *MutationDiffer) addDocDiff(missingFromSource, missingFromTarget map[uint32]map[string]*GetResult, srcDiff, tgtDiff, deletedFromSource, deletedFromTarget map[uint32]map[string][]*GetResult) {
	d.stateLock.Lock()
	defer d.stateLock.Unlock()

	for colId, missingFromSourcePerCol := range missingFromSource {
		if _, exists := d.missingFromSource[colId]; !exists {
			d.missingFromSource[colId] = make(map[string]*GetResult)
		}
		for key, result := range missingFromSourcePerCol {
			d.missingFromSource[colId][key] = result
		}
	}

	for colId, missingFromTargetPerCol := range missingFromTarget {
		if _, exists := d.missingFromTarget[colId]; !exists {
			d.missingFromTarget[colId] = make(map[string]*GetResult)
		}
		for key, result := range missingFromTargetPerCol {
			d.missingFromTarget[colId][key] = result
		}
	}

	for colId, srcDiffPerCol := range srcDiff {
		if _, exists := d.srcDiff[colId]; !exists {
			d.srcDiff[colId] = make(map[string][]*GetResult)
		}
		for key, results := range srcDiffPerCol {
			d.srcDiff[colId][key] = results
		}
	}

	for colId, tgtDiffPerCol := range tgtDiff {
		if _, exists := d.tgtDiff[colId]; !exists {
			d.tgtDiff[colId] = make(map[string][]*GetResult)
		}
		for key, results := range tgtDiffPerCol {
			d.tgtDiff[colId][key] = results
		}
	}

	for colId, deleteFromSourcePerCol := range deletedFromSource {
		if _, exists := d.deletedFromSource[colId]; !exists {
			d.deletedFromSource[colId] = make(map[string][]*GetResult)
		}
		for key, results := range deleteFromSourcePerCol {
			d.deletedFromSource[colId][key] = results
		}
	}
	for colId, deleteFromTargetPerCol := range deletedFromTarget {
		if _, exists := d.deletedFromTarget[colId]; !exists {
			d.deletedFromTarget[colId] = make(map[string][]*GetResult)
		}
		for key, results := range deleteFromTargetPerCol {
			d.deletedFromTarget[colId][key] = results
		}
	}
}

func (d *MutationDiffer) addKeysWithError(keysWithError MutationDiffFetchList) {
	d.stateLock.Lock()
	defer d.stateLock.Unlock()
	d.keysWithError = append(d.keysWithError, keysWithError...)
	atomic.AddUint32(&d.numKeysWithErrors, uint32(len(keysWithError)))
}

type DifferWorker struct {
	differ            *MutationDiffer
	fetchList         MutationDiffFetchList
	sourceBucketAgent *GocbcoreAgent
	targetBucketAgent *GocbcoreAgent
	sourceDcpAgent    *gocbcore.DCPAgent
	targetDcpAgent    *gocbcore.DCPAgent
	waitGroup         *sync.WaitGroup
	sourceResults     map[uint32]map[string]*GetResult
	targetResults     map[uint32]map[string]*GetResult
	resultsLock       sync.RWMutex
	logger            *xdcrLog.CommonLogger
	colIds            map[uint32][]uint32
	reverseColIds     map[uint32][]uint32
	migrationHintMap  MigrationHintMap
	compareType       string
	retries           int
}

func NewDifferWorker(differ *MutationDiffer, sourceDCPAgent, targetDCPAgent *gocbcore.DCPAgent, sourceBucketAgent,
	targetBucketAgent *GocbcoreAgent, fetchList MutationDiffFetchList, waitGroup *sync.WaitGroup, colIds,
	reverseColIds map[uint32][]uint32, migrationHintMap MigrationHintMap, compareType string, retries int) *DifferWorker {
	return &DifferWorker{
		differ:            differ,
		sourceBucketAgent: sourceBucketAgent,
		targetBucketAgent: targetBucketAgent,
		fetchList:         fetchList,
		waitGroup:         waitGroup,
		sourceResults:     make(map[uint32]map[string]*GetResult),
		targetResults:     make(map[uint32]map[string]*GetResult),
		logger:            differ.logger,
		sourceDcpAgent:    sourceDCPAgent,
		targetDcpAgent:    targetDCPAgent,
		colIds:            colIds,
		reverseColIds:     reverseColIds,
		migrationHintMap:  migrationHintMap,
		compareType:       compareType,
		retries:           retries,
	}
}

func compileReverseMap(srcToTgts map[uint32][]uint32) map[uint32][]uint32 {
	reverseMap := make(map[uint32][]uint32)

	for srcColId, tgtColIds := range srcToTgts {
		for _, tgtColId := range tgtColIds {
			if _, exists := reverseMap[tgtColId]; !exists {
				reverseMap[tgtColId] = []uint32{}
			}
			var srcExists bool
			for _, chkColId := range reverseMap[tgtColId] {
				if chkColId == srcColId {
					srcExists = true
					break
				}
			}
			if !srcExists {
				reverseMap[tgtColId] = append(reverseMap[tgtColId], srcColId)
			}
		}
	}
	return reverseMap
}

func (dw *DifferWorker) run() {
	defer dw.waitGroup.Done()
	dw.getResults()
	dw.diff()
}

func (dw *DifferWorker) getResults() {
	index := 0
	for {
		if index >= len(dw.fetchList) {
			break
		}

		if index+dw.differ.batchSize < len(dw.fetchList) {
			dw.sendBatchWithRetry(index, index+dw.differ.batchSize)
			index += dw.differ.batchSize
			continue
		}

		dw.sendBatchWithRetry(index, len(dw.fetchList))
		break
	}

}

func (dw *DifferWorker) sendBatchWithRetry(startIndex, endIndex int) {
	sendBatchFunc := func() error {
		batch := NewBatch(dw, startIndex, endIndex)
		err := batch.send()
		if err != nil {
			return err
		}
		dw.mergeResults(batch)
		return nil
	}

	opErr := utils.ExponentialBackoffExecutor("sendBatchWithRetry", dw.differ.sendBatchRetryInterval, dw.differ.maxNumOfSendBatchRetry,
		base.SendBatchBackoffFactor, dw.differ.sendBatchMaxBackoff, sendBatchFunc)
	if opErr != nil {
		dw.logger.Warnf("Skipped check on %v fetchList because of err=%v.\n", endIndex-startIndex, opErr)
		dw.differ.addKeysWithError(dw.fetchList[startIndex:endIndex])
	}
	// fetchList with error are also counted toward keysProcessed
	atomic.AddUint32(&dw.differ.numKeysProcessed, uint32(endIndex-startIndex))
}

// merge results obtained by batch into dw
// no need to lock results in dw since it is never accessed concurrently
// need to lock results in batch since it could still be updated when mergeResults is called
func (dw *DifferWorker) mergeResults(b *batch) {
	for colId, results := range b.sourceResults {
		if _, exists := dw.sourceResults[colId]; !exists {
			dw.sourceResults[colId] = make(map[string]*GetResult)
		}
		for key, result := range results {
			dw.sourceResults[colId][key] = result
		}
	}
	for colId, results := range b.targetResults {
		if _, exists := dw.targetResults[colId]; !exists {
			dw.targetResults[colId] = make(map[string]*GetResult)
		}
		for key, result := range results {
			dw.targetResults[colId][key] = result
		}
	}
}

func (dw *DifferWorker) diff() {
	missingFromSource := make(map[uint32]map[string]*GetResult)
	missingFromTarget := make(map[uint32]map[string]*GetResult)
	srcDiff := make(map[uint32]map[string][]*GetResult)
	tgtDiff := make(map[uint32]map[string][]*GetResult)
	deletedFromSource := make(map[uint32]map[string][]*GetResult)
	deletedFromTarget := make(map[uint32]map[string][]*GetResult)

	migrationMode := len(dw.migrationHintMap) > 0

	var includeBody bool
	var bodyOnly bool
	switch dw.compareType {
	case base.MutationCompareTypeBodyOnly:
		bodyOnly = true
	case base.MutationCompareTypeBodyAndMeta:
		includeBody = true
	}
	srcUUID, err := hlv.UUIDtoDocumentSource(dw.differ.sourceBucketUUID)
	if err != nil {
		// This error is very unusual, therefore panic
		dw.logger.Errorf("Error in converting the bucket UUID %v to required HLV format. err: %v", dw.differ.sourceBucketUUID, err)
		panic("bucketUUID convertion error")
	}
	tgtUUID, err1 := hlv.UUIDtoDocumentSource(dw.differ.targetBucketUUID)
	if err1 != nil {
		// This error is very unusual, therefore panic
		dw.logger.Errorf("Error in converting the bucket UUID %v to required HLV format. err: %v", dw.differ.targetBucketUUID, err1)
		panic("bucketUUID convertion error")
	}
	for srcColId, sourceResultMap := range dw.sourceResults {
		for key, sourceResult := range sourceResultMap {
			if sourceResult.key == "" {
				continue
			}
			var tgtColIds []uint32
			if migrationMode {
				tgtColIds = dw.migrationHintMap[key]
			} else {
				tgtColIds = dw.colIds[srcColId]
			}

			for _, tgtColId := range tgtColIds {
				var srcerr error
				var tgterr error
				targetResult := dw.targetResults[tgtColId][key]
				if targetResult.key == "" {
					continue
				}
				if bodyOnly {
					srcerr = sourceResult.bodyErr
					tgterr = targetResult.bodyErr
				} else {
					srcerr = sourceResult.metaErr
					tgterr = targetResult.metaErr
				}
				if isKeyNotFoundError(srcerr) && !isKeyNotFoundError(tgterr) {
					if _, exists := missingFromSource[srcColId]; !exists {
						missingFromSource[srcColId] = make(map[string]*GetResult)
					}
					missingFromSource[srcColId][key] = targetResult
					continue
				}
				if !isKeyNotFoundError(srcerr) && isKeyNotFoundError(tgterr) {
					if _, exists := missingFromTarget[tgtColId]; !exists {
						missingFromTarget[tgtColId] = make(map[string]*GetResult)
					}
					missingFromTarget[tgtColId][key] = sourceResult
					continue
				}
				if bodyOnly {
					if !areGetResultsBodyTheSame(sourceResult, targetResult) {
						if _, exists := srcDiff[srcColId]; !exists {
							srcDiff[srcColId] = make(map[string][]*GetResult)
						}
						srcDiff[srcColId][key] = append(srcDiff[srcColId][key], []*GetResult{sourceResult, targetResult}...)
						if _, exists := tgtDiff[tgtColId]; !exists {
							tgtDiff[tgtColId] = make(map[string][]*GetResult)
						}
						tgtDiff[tgtColId][key] = append(tgtDiff[tgtColId][key], []*GetResult{targetResult, sourceResult}...)
					}
				} else {
					metaSame, err := areGetResultsTheSame(sourceResult, targetResult, srcUUID, tgtUUID, includeBody)
					if err != nil {
						atomic.AddUint32(&dw.differ.numKeysWithErrors, 1)
						dw.logger.Errorf(err.Error())
						continue
					}
					if !metaSame {
						if isDeleted(sourceResult.GetMetaResult) {
							if _, exists := deletedFromSource[srcColId]; !exists {
								deletedFromSource[srcColId] = make(map[string][]*GetResult)
							}
							deletedFromSource[srcColId][key] = append(deletedFromSource[srcColId][key], []*GetResult{sourceResult, targetResult}...)
							continue
						}
						if isDeleted(targetResult.GetMetaResult) {
							if _, exists := deletedFromTarget[srcColId]; !exists {
								deletedFromTarget[srcColId] = make(map[string][]*GetResult)
							}
							deletedFromTarget[srcColId][key] = append(deletedFromSource[srcColId][key], []*GetResult{sourceResult, targetResult}...)
							continue
						}
						if _, exists := srcDiff[srcColId]; !exists {
							srcDiff[srcColId] = make(map[string][]*GetResult)
						}
						srcDiff[srcColId][key] = append(srcDiff[srcColId][key], []*GetResult{sourceResult, targetResult}...)
						if _, exists := tgtDiff[tgtColId]; !exists {
							tgtDiff[tgtColId] = make(map[string][]*GetResult)
						}
						tgtDiff[tgtColId][key] = append(tgtDiff[tgtColId][key], []*GetResult{targetResult, sourceResult}...)
					}
				}
			}
		}
	}
	// Need to do a double-take from target's point of view - check to see if certain things are missing from source
	for tgtColId, targetResultMap := range dw.targetResults {
		for key, targetResult := range targetResultMap {
			if targetResult.key == "" {
				continue
			}
			srcColIds := dw.reverseColIds[tgtColId]
			var foundSourceColId bool
			var keyExists bool
			for _, srcColId := range srcColIds {
				_, exists := dw.sourceResults[srcColId]
				if exists {
					foundSourceColId = true
					_, keyExists = dw.sourceResults[srcColId][key]
					break
				}
			}
			if !foundSourceColId || !keyExists {
				// This means that the source colId doesn't exist for this target entry
				if _, exists := missingFromTarget[tgtColId]; !exists {
					missingFromTarget[tgtColId] = make(map[string]*GetResult)
				}
				missingFromTarget[tgtColId][key] = targetResult
			}
		}
	}
	dw.differ.addDocDiff(missingFromSource, missingFromTarget, srcDiff, tgtDiff, deletedFromSource, deletedFromTarget)
}

type batch struct {
	dw                *DifferWorker
	fetchList         MutationDiffFetchList
	waitGroup         sync.WaitGroup
	sourceResultCount uint32
	targetResultCount uint32
	sourceResults     map[uint32]map[string]*GetResult
	targetResults     map[uint32]map[string]*GetResult
	resultsLock       sync.RWMutex
}

func NewBatch(dw *DifferWorker, startIndex, endIndex int) *batch {
	b := &batch{
		dw:            dw,
		fetchList:     dw.fetchList[startIndex:endIndex],
		sourceResults: make(map[uint32]map[string]*GetResult),
		targetResults: make(map[uint32]map[string]*GetResult),
	}
	// initialize all entries in results map
	// update to *GetResult in map will not be treated as concurrent update to map itself
	b.resultsLock.Lock()
	defer b.resultsLock.Unlock()
	for _, fetchItem := range b.fetchList {
		if _, exists := b.sourceResults[fetchItem.SrcColId]; !exists {
			b.sourceResults[fetchItem.SrcColId] = make(map[string]*GetResult)
		}
		b.sourceResults[fetchItem.SrcColId][fetchItem.Key] = &GetResult{key: fetchItem.Key}
		for _, tgtColId := range fetchItem.TgtColIds {
			if _, exists := b.targetResults[tgtColId]; !exists {
				b.targetResults[tgtColId] = make(map[string]*GetResult)
			}
			b.targetResults[tgtColId][fetchItem.Key] = &GetResult{key: fetchItem.Key}
		}
	}
	return b
}

// When data is in flight, the results may be different. If results are different
// then try a few times to see if the same CAS are ever the same. If they are, then it means
// this is not a diff
func (b *batch) send() error {
	for _, fetchItem := range b.fetchList {
		b.get(fetchItem.Key, true, b.dw.differ.compareType, fetchItem.SrcColId)
		for _, tgtId := range fetchItem.TgtColIds {
			b.get(fetchItem.Key, false, b.dw.differ.compareType, tgtId)
		}
	}

	doneChan := make(chan bool, 1)
	go utils.WaitForWaitGroup(&b.waitGroup, doneChan)

	timer := time.NewTimer(time.Duration(b.dw.differ.timeout) * time.Second)
	defer timer.Stop()
	for {
		select {
		case <-doneChan:
			return nil
		case <-timer.C:
			return fmt.Errorf("mutation differ batch timed out")
		}
	}
}

func (b *batch) get(key string, isSource bool, compareType string, colId uint32) {
	getCallbackFunc := func(result *gocbcore.GetResult, err error) {
		b.resultsLock.RLock()
		var resultsMap map[string]*GetResult
		if isSource {
			resultsMap = b.sourceResults[colId]
		} else {
			resultsMap = b.targetResults[colId]
		}
		getResult := resultsMap[key]
		b.resultsLock.RUnlock()

		getResult.lock.Lock()
		defer getResult.lock.Unlock()
		if err != nil {
			getResult.bodyErr = err
		} else {
			getResult.Value = result.Value
		}
		b.waitGroup.Done()
	}

	getMetaCallbackFunc := func(result *gocbcore.GetMetaResult, err error) {
		b.resultsLock.RLock()
		var resultsMap map[string]*GetResult
		if isSource {
			resultsMap = b.sourceResults[colId]
		} else {
			resultsMap = b.targetResults[colId]
		}
		getResult := resultsMap[key]
		b.resultsLock.RUnlock()

		getResult.lock.Lock()
		defer getResult.lock.Unlock()

		getResult.GetMetaResult = result
		getResult.metaErr = err
		b.waitGroup.Done()
	}

	getHlvCallbackFunc := func(result *gocbcore.LookupInResult, err error) {
		b.resultsLock.RLock()
		var resultsMap map[string]*GetResult
		var bucketUUID string
		if isSource {
			resultsMap = b.sourceResults[colId]
			bucketUUID = b.dw.differ.sourceBucketUUID
		} else {
			resultsMap = b.targetResults[colId]
			bucketUUID = b.dw.differ.targetBucketUUID
		}
		getResult := resultsMap[key]
		b.resultsLock.RUnlock()

		if err != nil {
			b.dw.logger.Errorf("Subdoc-get error occured for doc %v. err:%v\n", key, err)
		} else {
			getResult.lock.Lock()
			defer getResult.lock.Unlock()
			getResult.HLV, getResult.importCas, getResult.parsingErr = getHlvImportCas(bucketUUID, result)
		}
		b.waitGroup.Done()
	}

	var err error
	var err1 error
	var err2 error
	var gocbAgent *GocbcoreAgent
	if isSource {
		gocbAgent = b.dw.sourceBucketAgent
	} else {
		gocbAgent = b.dw.targetBucketAgent
	}
	if compareType == base.MutationCompareTypeBodyOnly {
		b.waitGroup.Add(1)
		err = gocbAgent.Get(key, getCallbackFunc, colId)
		if err != nil {
			b.dw.logger.Errorf("GetError for bucket %v on key %v. err: %v\n", gocbAgent.GocbcoreAgentCommon.BucketName, key, err)
		}
	} else if compareType == base.MutationCompareTypeMetadata {
		b.waitGroup.Add(2)
		err = gocbAgent.GetMeta(key, getMetaCallbackFunc, colId)
		if err != nil {
			b.dw.logger.Errorf("GetMetaError for bucket %v on key %v. err: %v\n", gocbAgent.GocbcoreAgentCommon.BucketName, key, err)
		}
		err1 = gocbAgent.GetHlv(key, getHlvCallbackFunc, colId)
		if err1 != nil {
			b.dw.logger.Errorf("GetHlvError for bucket %v on key %v. err: %v\n", gocbAgent.GocbcoreAgentCommon.BucketName, key, err1)
		}
	} else if compareType == base.MutationCompareTypeBodyAndMeta {
		b.waitGroup.Add(3)
		err = gocbAgent.Get(key, getCallbackFunc, colId)
		if err != nil {
			b.dw.logger.Errorf("GetError for bucket %v on key %v. err: %v\n", gocbAgent.GocbcoreAgentCommon.BucketName, key, err)
		}
		err1 = gocbAgent.GetMeta(key, getMetaCallbackFunc, colId)
		if err1 != nil {
			b.dw.logger.Errorf("GetMetaError for bucket %v on key %v. err: %v\n", gocbAgent.GocbcoreAgentCommon.BucketName, key, err1)
		}
		err2 = gocbAgent.GetHlv(key, getHlvCallbackFunc, colId)
		if err2 != nil {
			b.dw.logger.Errorf("GetHlvError for bucket %v on key %v. err: %v\n", gocbAgent.GocbcoreAgentCommon.BucketName, key, err2)
		}
	}
}

func isKeyNotFoundError(err error) bool {
	return err != nil && strings.Contains(err.Error(), gocbcore.ErrDocumentNotFound.Error())
}

func areGetResultsBodyTheSame(result1, result2 *GetResult) bool {

	if result1.Value == nil {
		return result2.Value == nil
	}
	if result2.Value == nil {
		return false
	}

	return reflect.DeepEqual(result1.Value, result2.Value)
}

func areGetResultsTheSame(result1, result2 *GetResult, sourceUUID, targetUUID hlv.DocumentSourceId, includeBody bool) (bool, error) {
	if result1.GetMetaResult == nil && result2.GetMetaResult == nil {
		return true, nil
	} else if result1.GetMetaResult == nil {
		if isDeleted(result2.GetMetaResult) {
			return true, nil
		} else {
			return false, nil
		}
	} else if result2.GetMetaResult == nil {
		if isDeleted(result1.GetMetaResult) {
			return true, nil
		} else {
			return false, nil
		}
	} else if isDeleted(result1.GetMetaResult) && isDeleted(result2.GetMetaResult) {
		return true, nil
	} else {
		// Only compare json and Xattr bits of the datatype
		if result1.parsingErr != nil || result2.parsingErr != nil {
			return false, fmt.Errorf("Cannot compare metadata for document with key %v due to HLV parsing error either at the source or at target. SourceErr: %v TargetError: %v", result1.key, result1.parsingErr, result2.parsingErr)
		}
		metaSame := result1.Cas == result2.Cas && result1.SeqNo == result2.SeqNo && result1.Flags == result2.Flags &&
			result1.Expiry == result2.Expiry && result1.Deleted == result2.Deleted && (result1.Datatype&base.JSONDataType == result2.Datatype&base.JSONDataType) &&
			(result1.Datatype&xdcrBase.XattrDataType == result2.Datatype&xdcrBase.XattrDataType) && compareHlv(result1.HLV, result2.HLV, uint64(result1.Cas), uint64(result2.Cas), sourceUUID, targetUUID)

		if includeBody {
			bodySame := areGetResultsBodyTheSame(result1, result2)
			return (metaSame && bodySame), nil
		}
		return metaSame, nil
	}
}

func getHlvImportCas(bucketUUID string, result *gocbcore.LookupInResult) (Hlv *hlv.HLV, importCas uint64, err error) {
	if result == nil {
		return
	}
	var importCasBytes []byte
	var hlvBytes []byte
	if result.Ops[1].Err == nil {
		importCasBytes = result.Ops[1].Value
	}
	if result.Ops[0].Err == nil {
		hlvBytes = result.Ops[0].Value
	}
	importLen := len(importCasBytes)
	hlvLen := len(hlvBytes)
	if importCasBytes != nil && importLen != 0 {
		// Remove the start/end quotes before converting it to uint64
		importCas, err = xdcrBase.HexLittleEndianToUint64(importCasBytes[1 : importLen-1])
		if err != nil {
			return
		}
	}
	if hlvBytes != nil && hlvLen != 0 {
		var bucketId hlv.DocumentSourceId
		bucketId, err = hlv.UUIDtoDocumentSource(bucketUUID)
		if err != nil {
			err = fmt.Errorf("Error occured while converting the bucket UUID %v to HLV required format. err: %v", bucketUUID, err)
			return
		}
		Hlv, err = constructHlv(uint64(result.Cas), importCas, bucketId, hlvBytes)
	}
	return
}

func isDeleted(result *gocbcore.GetMetaResult) bool {
	if result != nil {
		return result.Deleted != 0
	}
	return false
}

type GetResult struct {
	key        string
	Value      []byte
	importCas  uint64
	bodyErr    error
	metaErr    error
	parsingErr error
	*gocbcore.GetMetaResult
	*hlv.HLV
	lock sync.RWMutex
}

func (d *MutationDiffer) initialize() error {
	var err error
	err = d.openBucket(d.sourceBucketName, d.sourceReference, true)
	if err != nil {
		return err
	}
	err = d.openBucket(d.targetBucketName, d.targetReference, false)
	if err != nil {
		return err
	}
	return nil
}

func (d *MutationDiffer) openBucket(bucketName string, reference *metadata.RemoteClusterReference, source bool) error {
	var capability = d.srcCapability
	if !source {
		capability = d.tgtCapability
	}

	name := "xdcrDifferMutationDiffer_"
	if source {
		name += "src"
	} else {
		name += "dst"
	}

	connStr, err := reference.MyConnectionStr()
	if err != nil {
		return err
	}

	var auth interface{}
	pwAuth := base.PasswordAuth{
		Username: reference.UserName(),
		Password: reference.Password(),
	}

	err = d.initializeKVVBMap(source)
	if err != nil {
		return err
	}

	if reference.HttpAuthMech() == xdcrBase.HttpAuthMechHttps {
		auth = &base.CertificateAuth{
			PasswordAuth:     pwAuth,
			CertificateBytes: reference.Certificates(),
		}
		err = d.initializeKvSSLMap(source)
		if err != nil {
			return err
		}
		err = d.initializeKVVBMap(source)
		if err != nil {
			return err
		}
		// For SSL, the connStr will be secure SSL port to KV directly through CCCP
		var sslPort uint16
		var kvVbMap = d.srcKvVbMap
		var sslPortMap = d.srcKvSSLPortMap
		if !source {
			kvVbMap = d.tgtKvVbMap
			sslPortMap = d.tgtKvSSLPortMap
		}
		for k, _ := range kvVbMap {
			connStr = k
			break
		}
		sslPort, found := sslPortMap[connStr]
		if !found {
			return fmt.Errorf("Cannot find SSL port for %v in map %v", connStr, sslPortMap)
		}
		connStr = xdcrBase.GetHostAddr(xdcrBase.GetHostName(connStr), sslPort)
		base.TagCouchbaseSecurePrefix(&connStr)
	} else {
		auth = &pwAuth
		base.TagHttpPrefix(&connStr)
	}

	agent, err := NewGocbcoreAgent(name, []string{connStr}, bucketName, auth, d.batchSize, capability)

	if source {
		d.sourceBucketAgent = agent
	} else {
		d.targetBucketAgent = agent
	}
	return err
}

func (d *MutationDiffer) initializeKvSSLMap(source bool) error {
	var err error
	var connStr string
	if source {
		connStr, err = d.sourceReference.MyConnectionStr()
	} else {
		connStr, err = d.targetReference.MyConnectionStr()
	}
	if err != nil {
		return err
	}

	if source {
		d.srcKvSSLPortMap, err = d.utils.GetMemcachedSSLPortMap(connStr, d.sourceReference.UserName(),
			d.sourceReference.Password(), d.sourceReference.HttpAuthMech(), d.sourceReference.Certificates(),
			d.sourceReference.SANInCertificate(), d.sourceReference.ClientCertificate(), d.sourceReference.ClientKey(),
			d.sourceBucketName, d.logger, false)
	} else {
		d.tgtKvSSLPortMap, err = d.utils.GetMemcachedSSLPortMap(connStr, d.targetReference.UserName(),
			d.targetReference.Password(), d.targetReference.HttpAuthMech(), d.targetReference.Certificates(),
			d.targetReference.SANInCertificate(), d.targetReference.ClientCertificate(), d.targetReference.ClientKey(),
			d.targetBucketName, d.logger, false)
	}
	return nil
}

func (d *MutationDiffer) initializeKVVBMap(source bool) error {
	var err error
	var connStr string
	if source {
		connStr, err = d.sourceReference.MyConnectionStr()
	} else {
		connStr, err = d.targetReference.MyConnectionStr()
	}
	if err != nil {
		return err
	}

	if source {
		_, _, _, _, _, d.srcKvVbMap, err = d.utils.BucketValidationInfo(connStr, d.sourceBucketName, d.sourceReference.UserName(),
			d.sourceReference.Password(), d.sourceReference.HttpAuthMech(), d.sourceReference.Certificates(),
			d.sourceReference.SANInCertificate(), d.sourceReference.ClientCertificate(), d.sourceReference.ClientKey(),
			d.logger)
	} else {
		_, _, _, _, _, d.tgtKvVbMap, err = d.utils.BucketValidationInfo(connStr, d.targetBucketName, d.targetReference.UserName(),
			d.targetReference.Password(), d.targetReference.HttpAuthMech(), d.targetReference.Certificates(),
			d.targetReference.SANInCertificate(), d.targetReference.ClientCertificate(), d.targetReference.ClientKey(),
			d.logger)
	}

	return err
}

func resultMapContainsAtLeastOne(generic interface{}) bool {
	switch generic.(type) {
	case map[uint32]map[string]*GetResult:
		uintMap := generic.(map[uint32]map[string]*GetResult)
		for _, vMap := range uintMap {
			if len(vMap) > 0 {
				return true
			}
		}
	case map[uint32]map[string][]*GetResult:
		uintMap := generic.(map[uint32]map[string][]*GetResult)
		for _, vMap := range uintMap {
			if len(vMap) > 0 {
				return true
			}
		}
	default:
		panic(fmt.Sprintf("Invalid type %v", reflect.TypeOf(generic)))
	}
	return false
}

func (d *MutationDiffer) containsDiff() bool {
	d.stateLock.RLock()
	defer d.stateLock.RUnlock()

	return resultMapContainsAtLeastOne(d.missingFromSource) || resultMapContainsAtLeastOne(d.missingFromTarget) ||
		resultMapContainsAtLeastOne(d.srcDiff) || resultMapContainsAtLeastOne(d.tgtDiff) ||
		resultMapContainsAtLeastOne(d.deletedFromSource) || resultMapContainsAtLeastOne(d.deletedFromTarget)
}

func resultMapToDiffKeysMap(generic interface{}) DiffKeysMap {
	resultMap := make(DiffKeysMap)

	switch generic.(type) {
	case map[uint32]map[string]*GetResult:
		uintMap := generic.(map[uint32]map[string]*GetResult)
		for colId, strMap := range uintMap {
			if _, exists := resultMap[colId]; !exists {
				resultMap[colId] = []string{}
			}
			for key, _ := range strMap {
				resultMap[colId] = append(resultMap[colId], key)
			}
		}
	case map[uint32]map[string][]*GetResult:
		uintMap := generic.(map[uint32]map[string][]*GetResult)
		for colId, strMap := range uintMap {
			if _, exists := resultMap[colId]; !exists {
				resultMap[colId] = []string{}
			}
			for key, _ := range strMap {
				resultMap[colId] = append(resultMap[colId], key)
			}
		}
	default:
		panic(fmt.Sprintf("Invalid type %v", reflect.TypeOf(generic)))
	}
	return resultMap
}

func (d *MutationDiffer) getDiffKeysFromSourceGocbResult() DiffKeysMap {
	d.stateLock.RLock()
	defer d.stateLock.RUnlock()

	resultMap := make(DiffKeysMap)
	resultMap.Merge(resultMapToDiffKeysMap(d.missingFromSource))
	resultMap.Merge(resultMapToDiffKeysMap(d.srcDiff))
	resultMap.Merge(resultMapToDiffKeysMap(d.deletedFromSource))
	return resultMap
}

func (d *MutationDiffer) getDiffKeysFromTargetGocbResult() DiffKeysMap {
	d.stateLock.RLock()
	defer d.stateLock.RUnlock()

	resultMap := make(DiffKeysMap)
	resultMap.Merge(resultMapToDiffKeysMap(d.missingFromTarget))
	resultMap.Merge(resultMapToDiffKeysMap(d.tgtDiff))
	resultMap.Merge(resultMapToDiffKeysMap(d.deletedFromTarget))
	return resultMap
}

func (d *MutationDiffer) clearGoCbResults() {
	d.stateLock.Lock()
	defer d.stateLock.Unlock()

	d.missingFromSource = make(map[uint32]map[string]*GetResult)
	d.missingFromTarget = make(map[uint32]map[string]*GetResult)
	d.srcDiff = make(map[uint32]map[string][]*GetResult)
	d.tgtDiff = make(map[uint32]map[string][]*GetResult)
	d.deletedFromSource = make(map[uint32]map[string][]*GetResult)
	d.deletedFromTarget = make(map[uint32]map[string][]*GetResult)
}

func (d *MutationDiffer) writeMigrationDetails() error {
	fileName := base.MutationDiffMigrationDetails
	srcMapFilename := d.mutationDifferFileDir + base.FileDirDelimiter + fileName

	bytes, err := json.Marshal(d.duplicateMap.ToIntMap())
	if err != nil {
		return err
	}
	err = os.WriteFile(srcMapFilename, bytes, 0644)
	if err != nil {
		return err
	}
	return nil
}
